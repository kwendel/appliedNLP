{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replicating paper results\n",
    "This notebook will be used for replicating the results that are achieved in the paper. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "\n",
    "data_path = '../features/2019-04-04_202426'\n",
    "feature_path = 'features.pkl'\n",
    "label_path = 'labels.npy'\n",
    "\n",
    "features = pd.read_pickle(path.join(data_path, feature_path))\n",
    "labels = np.load(path.join(data_path, label_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute class priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "n_nonclickbait = counts[0]\n",
    "n_clickbait = counts[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "Below is a list of the features that are going to be used.\n",
    "\n",
    "**Note**:\n",
    "The features are a subset of all the features that are being used in the original.\n",
    "We expect that scores will be slightly lower as we have less information about the post and the article. Still, the overal trend is expected to be the same because their results also so that the differences between using all features and 20 features is only a marginal improvement. \n",
    "\n",
    "Expected results training set\n",
    "\n",
    "| Measure   | Interval      |\n",
    "|-----------|---------------|\n",
    "| AUC       | 0.583 - 0.715 |\n",
    "| Accuracy  | 0.636 - 0.732 |\n",
    "| Precision | 0.743 - 0.75  |\n",
    "| Recall    | 0.721 - 0.92  |\n",
    "\n",
    "\n",
    "Expected results validation set  \n",
    "\n",
    "| Measure   | Interval      |\n",
    "|-----------|---------------|\n",
    "| AUC       | 0.653 - 0.8   |\n",
    "| Accuracy  | 0.725 - 0.812 |\n",
    "| Precision | 0.814 - 0.824 |\n",
    "| Recall    | 0.811 - 0.966 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['numChars_post_title', 'numChars_post_image', 'numChars_article_kw',\n",
      "       'numChars_article_desc', 'numChars_article_title',\n",
      "       'numChars_article_par', 'numWords_post_title', 'numWords_post_image',\n",
      "       'numWords_article_kw', 'numWords_article_desc',\n",
      "       ...\n",
      "       'diffStopWords_post_image_article_kw',\n",
      "       'diffStopWords_post_image_article_desc',\n",
      "       'diffStopWords_post_image_article_title',\n",
      "       'diffStopWords_post_image_article_par',\n",
      "       'diffStopWords_article_kw_article_desc',\n",
      "       'diffStopWords_article_kw_article_title',\n",
      "       'diffStopWords_article_kw_article_par',\n",
      "       'diffStopWords_article_desc_article_title',\n",
      "       'diffStopWords_article_desc_article_par',\n",
      "       'diffStopWords_article_title_article_par'],\n",
      "      dtype='object', length=150)\n"
     ]
    }
   ],
   "source": [
    "print(features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization by grid search\n",
    "\n",
    "The authors did not explain what parameters their optimal classifier used. They also did not explain how these classifier where optimized.\n",
    "\n",
    "Therefore, we made the decision to apply a grid search to find suitable parameters (such as #estimators etc.). The grids are given below.\n",
    "\n",
    "The following settings are used during this grid search: \n",
    "- **10-fold cross validation with shuffeled data.** This will remove bias from our estimation as the data is shuffeld and the cross validation is a different one then used during testing. \n",
    "- **F1-metric as performance measure.** The classes of clickbait vs no-clickbait are unbalanced, making measure as accuracy useless (70% accuracy could mean that we only assign to one class!). As we want the performance for both classes to be equally good, the F1 score is used which is the harmonic mean of precision and recall. \n",
    "\n",
    "## GRIDS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_grid = {\n",
    "    'criterion': ['entropy', 'gini'],\n",
    "    'n_estimators': [10,25,50,100],\n",
    "    'max_depth': [1,3,5,None],\n",
    "    'max_features': [5,10,15, None],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "adaboost_grid = {\n",
    "    'n_estimators': [10,25,50,100],\n",
    "    'learning_rate': [0.1,0.2,0.3],\n",
    "    'base_estimator__max_depth': [1,3,5,None],\n",
    "    'base_estimator__criterion': ['entropy', 'gini'],\n",
    "    'base_estimator__class_weight': ['balanced', None]\n",
    "    \n",
    "}\n",
    "\n",
    "xgb_grid = {\n",
    "    'objective': ['binary:logistic'],\n",
    "    'learning_rate': [0.1,0.2,0.3],\n",
    "    'n_estimators': [10,25,50,100],\n",
    "    'max_depth': [1,3,5,7,9],\n",
    "    'scale_pos_weight': [1, n_nonclickbait / n_clickbait, n_clickbait / n_nonclickbait] \n",
    "}\n",
    "\n",
    "# This classifier does not really have parameters to tweak\n",
    "# Use default values to not break the pipeline\n",
    "naivebayes_grid = {\n",
    "    'priors': [None], # priors are computed by the algorithm\n",
    "    'var_smoothing': [1e-9]\n",
    "}\n",
    "\n",
    "svc_grid = {\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "classifiers_options = [\n",
    "    {\n",
    "        'name': 'RandomForest',\n",
    "        'clf': RandomForestClassifier(),\n",
    "#         'grid': randomforest_grid\n",
    "        'optimized_param': {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'max_features': 15, 'n_estimators': 100}\n",
    "    },\n",
    "    {\n",
    "        'name': 'XGDBoost',\n",
    "        'clf': XGBClassifier(),\n",
    "#         'grid': xgb_grid\n",
    "        'optimized_param': {'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 25, 'objective': 'binary:logistic', 'scale_pos_weight': 2.227034120734908}\n",
    "    },\n",
    "    {\n",
    "        'name': 'GaussianNaiveBays',\n",
    "        'clf': GaussianNB(),\n",
    "        'optimized_param': {} ## Can not be optimized\n",
    "\n",
    "    },\n",
    "    {\n",
    "        'name': 'AdaBoost',\n",
    "        'clf': AdaBoostClassifier(DecisionTreeClassifier()),\n",
    "#         'grid': adaboost_grid\n",
    "        'optimized_param': {'base_estimator__class_weight': 'balanced', 'base_estimator__criterion': 'gini', 'base_estimator__max_depth': 1, 'learning_rate': 0.2, 'n_estimators': 50}\n",
    "    },\n",
    "    # Takes to long to optimize so we just assume that the linear kernel is good enough\n",
    "#     {\n",
    "#         'name': 'SVM',\n",
    "#         'clf': SVC(probability=True),\n",
    "# # #         'grid': svc_grid,\n",
    "#         'optimized_param': {'kernel': 'linear'}\n",
    "#     }\n",
    "]\n",
    "\n",
    "import classification\n",
    "classifiers = classification.Classifiers(features,labels, classifiers_options)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform the grid search - optimize on F1\n",
    "\n",
    "This may take a while.  \n",
    "Output = optimized settings per classifier, which can be used in the model with the `optimized_param` key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Start optimizing by grid search --\n",
      "Optimizing: RandomForest\n",
      "Optimal settings RandomForest:\n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'max_features': 15, 'n_estimators': 100}\n",
      "Optimizing: XGDBoost\n",
      "Optimal settings XGDBoost:\n",
      "{'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 25, 'objective': 'binary:logistic', 'scale_pos_weight': 2.227034120734908}\n",
      "Optimizing: AdaBoost\n",
      "Optimal settings AdaBoost:\n",
      "{'base_estimator__class_weight': 'balanced', 'base_estimator__criterion': 'gini', 'base_estimator__max_depth': 1, 'learning_rate': 0.2, 'n_estimators': 50}\n",
      "-- Finished optimizing -- \n"
     ]
    }
   ],
   "source": [
    "classifiers.optimize(metric='f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance - optimized on F1\n",
    "\n",
    "The authors test their classifiers by doing a 10-fold internal (?) cross validation. To have a fair comparison, we will use the same strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Cross validation with 10-folds --\n",
      "Cross validation performance RandomForest:\n",
      "TRAIN\n",
      "train_accuracy     0.720438\n",
      "train_precision    0.542794\n",
      "train_f1           0.580049\n",
      "train_roc_auc      0.768475\n",
      "train_recall       0.623038\n",
      "\n",
      "TEST\n",
      "test_accuracy     0.671417\n",
      "test_precision    0.476475\n",
      "test_f1           0.507665\n",
      "test_roc_auc      0.691357\n",
      "test_recall       0.546137\n",
      "\n",
      "\n",
      "Cross validation performance XGDBoost:\n",
      "TRAIN\n",
      "train_accuracy     0.808730\n",
      "train_precision    0.660463\n",
      "train_f1           0.718524\n",
      "train_roc_auc      0.890174\n",
      "train_recall       0.787892\n",
      "\n",
      "TEST\n",
      "test_accuracy     0.670199\n",
      "test_precision    0.474328\n",
      "test_f1           0.515638\n",
      "test_roc_auc      0.702012\n",
      "test_recall       0.571936\n",
      "\n",
      "\n",
      "Cross validation performance GaussianNaiveBays:\n",
      "TRAIN\n",
      "train_accuracy     0.629974\n",
      "train_precision    0.443805\n",
      "train_f1           0.516139\n",
      "train_roc_auc      0.675467\n",
      "train_recall       0.636787\n",
      "\n",
      "TEST\n",
      "test_accuracy     0.622641\n",
      "test_precision    0.436469\n",
      "test_f1           0.506364\n",
      "test_roc_auc      0.654014\n",
      "test_recall       0.619653\n",
      "\n",
      "\n",
      "Cross validation performance AdaBoost:\n",
      "TRAIN\n",
      "train_accuracy     0.705571\n",
      "train_precision    0.519665\n",
      "train_f1           0.581496\n",
      "train_roc_auc      0.766060\n",
      "train_recall       0.660138\n",
      "\n",
      "TEST\n",
      "test_accuracy     0.665734\n",
      "test_precision    0.469947\n",
      "test_f1           0.529499\n",
      "test_roc_auc      0.700846\n",
      "test_recall       0.611832\n",
      "\n",
      "\n",
      "-- Finished cross validation --\n"
     ]
    }
   ],
   "source": [
    "classifiers.cross_val()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results show that some classifiers have a extremely low recall. We dont have access to the actual predictions that were made, so to analyse the results we do another test on a random subset. This gives us access to the confusion matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Performance on split: 70% train - 30% split --\n",
      "Test performance: RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "no-clickbait       0.77      0.71      0.74       513\n",
      "   clickbait       0.44      0.52      0.47       225\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       738\n",
      "   macro avg       0.60      0.61      0.61       738\n",
      "weighted avg       0.67      0.65      0.66       738\n",
      "\n",
      "AUC on binary labels: 0.6125536062378167\n",
      "AUC on probabilities: 0.6265713666883258\n",
      "Confusion matrix:\n",
      "[[364 149]\n",
      " [109 116]]\n",
      "\n",
      "\n",
      "Test performance: XGDBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "no-clickbait       0.78      0.70      0.74       519\n",
      "   clickbait       0.43      0.54      0.48       219\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       738\n",
      "   macro avg       0.61      0.62      0.61       738\n",
      "weighted avg       0.68      0.65      0.66       738\n",
      "\n",
      "AUC on binary labels: 0.6191173753530235\n",
      "AUC on probabilities: 0.6707577797133581\n",
      "Confusion matrix:\n",
      "[[363 156]\n",
      " [101 118]]\n",
      "\n",
      "\n",
      "Test performance: GaussianNaiveBays\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "no-clickbait       0.77      0.62      0.69       502\n",
      "   clickbait       0.42      0.60      0.50       236\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       738\n",
      "   macro avg       0.60      0.61      0.59       738\n",
      "weighted avg       0.66      0.61      0.62       738\n",
      "\n",
      "AUC on binary labels: 0.6084897697346209\n",
      "AUC on probabilities: 0.6408898305084745\n",
      "Confusion matrix:\n",
      "[[311 191]\n",
      " [ 95 141]]\n",
      "\n",
      "\n",
      "Test performance: AdaBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "no-clickbait       0.76      0.70      0.73       493\n",
      "   clickbait       0.47      0.55      0.51       245\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       738\n",
      "   macro avg       0.61      0.62      0.62       738\n",
      "weighted avg       0.66      0.65      0.65       738\n",
      "\n",
      "AUC on binary labels: 0.6223537690938443\n",
      "AUC on probabilities: 0.6704847456223869\n",
      "Confusion matrix:\n",
      "[[344 149]\n",
      " [111 134]]\n",
      "\n",
      "\n",
      "-- Finished test reports --\n"
     ]
    }
   ],
   "source": [
    "classifiers.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance - optimized on Recall\n",
    "\n",
    "The results above show that the classifiers have a hard time with getting a good recall score, especially on the clickbait class which has less samples. This means that the samples that are classified as clickbait is only a small fraction of the total clickbait posts. \n",
    "\n",
    "When we look at the paper, we see that they have a outstanding recall score and its higher than all other metrics that are provided. This could indicate that they decide that to optimize on the recall metric. As we have a binary classification problem (clickbait vs no-clickbait), the recall measure can be seen as the probability of detection (sort of)(wikipedia source). So optimizing on this metric makes sense in the clickbait context, as we want to make sure that we our detection is correct (and thus make a small amount of False negatives).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "classifiers_options = [\n",
    "    {\n",
    "        'name': 'RandomForest',\n",
    "        'clf': RandomForestClassifier(),\n",
    "#         'grid': randomforest_grid\n",
    "        'optimized_param': {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'max_features': 15, 'n_estimators': 10}\n",
    "    },\n",
    "    {\n",
    "        'name': 'XGDBoost',\n",
    "        'clf': XGBClassifier(),\n",
    "#         'grid': xgb_grid\n",
    "        'optimized_param': {'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 100, 'objective': 'binary:logistic', 'scale_pos_weight': 2.227034120734908}\n",
    "    },\n",
    "    {\n",
    "        'name': 'GaussianNaiveBays',\n",
    "        'clf': GaussianNB(),\n",
    "        'optimized_param': {} ## Can not be optimized\n",
    "    },\n",
    "    {\n",
    "        'name': 'AdaBoost',\n",
    "        'clf': AdaBoostClassifier(DecisionTreeClassifier()),\n",
    "#         'grid': adaboost_grid\n",
    "        'optimized_param': {'base_estimator__class_weight': 'balanced', 'base_estimator__criterion': 'gini', 'base_estimator__max_depth': 1, 'learning_rate': 0.3, 'n_estimators': 10} \n",
    "    },\n",
    "#     {\n",
    "#         'name': 'SVM',\n",
    "#         'clf': SVC(probability=True),\n",
    "# #         'grid': svc_grid,\n",
    "#         'optimized_param': {'kernel': 'linear'}\n",
    "#     }\n",
    "]\n",
    "\n",
    "import classification\n",
    "classifiers = classification.Classifiers(features,labels, classifiers_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Start optimizing by grid search --\n",
      "Optimizing: RandomForest\n",
      "Optimal settings RandomForest:\n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 3, 'max_features': 15, 'n_estimators': 10}\n",
      "Optimizing: XGDBoost\n",
      "Optimal settings XGDBoost:\n",
      "{'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 100, 'objective': 'binary:logistic', 'scale_pos_weight': 2.227034120734908}\n",
      "Optimizing: AdaBoost\n",
      "Optimal settings AdaBoost:\n",
      "{'base_estimator__class_weight': 'balanced', 'base_estimator__criterion': 'gini', 'base_estimator__max_depth': 1, 'learning_rate': 0.3, 'n_estimators': 10}\n",
      "-- Finished optimizing -- \n"
     ]
    }
   ],
   "source": [
    "classifiers.optimize(metric='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Cross validation with 10-folds --\n",
      "Cross validation performance RandomForest:\n",
      "TRAIN\n",
      "train_accuracy     0.698657\n",
      "train_precision    0.511935\n",
      "train_f1           0.553291\n",
      "train_roc_auc      0.737571\n",
      "train_recall       0.603119\n",
      "\n",
      "TEST\n",
      "test_accuracy     0.655147\n",
      "test_precision    0.449339\n",
      "test_f1           0.482847\n",
      "test_roc_auc      0.665696\n",
      "test_recall       0.524120\n",
      "\n",
      "\n",
      "Cross validation performance XGDBoost:\n",
      "TRAIN\n",
      "train_accuracy     0.702770\n",
      "train_precision    0.516060\n",
      "train_f1           0.579131\n",
      "train_roc_auc      0.763872\n",
      "train_recall       0.659901\n",
      "\n",
      "TEST\n",
      "test_accuracy     0.658804\n",
      "test_precision    0.460696\n",
      "test_f1           0.511556\n",
      "test_roc_auc      0.704153\n",
      "test_recall       0.580045\n",
      "\n",
      "\n",
      "Cross validation performance GaussianNaiveBays:\n",
      "TRAIN\n",
      "train_accuracy     0.629208\n",
      "train_precision    0.443776\n",
      "train_f1           0.515361\n",
      "train_roc_auc      0.675457\n",
      "train_recall       0.637850\n",
      "\n",
      "TEST\n",
      "test_accuracy     0.615701\n",
      "test_precision    0.431155\n",
      "test_f1           0.500378\n",
      "test_roc_auc      0.656429\n",
      "test_recall       0.618240\n",
      "\n",
      "\n",
      "Cross validation performance AdaBoost:\n",
      "TRAIN\n",
      "train_accuracy     0.663504\n",
      "train_precision    0.468248\n",
      "train_f1           0.537148\n",
      "train_roc_auc      0.711242\n",
      "train_recall       0.630074\n",
      "\n",
      "TEST\n",
      "test_accuracy     0.638055\n",
      "test_precision    0.437716\n",
      "test_f1           0.503037\n",
      "test_roc_auc      0.673651\n",
      "test_recall       0.594012\n",
      "\n",
      "\n",
      "-- Finished cross validation --\n"
     ]
    }
   ],
   "source": [
    "classifiers.cross_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Performance on split: 70% train - 30% split --\n",
      "Test performance: RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "no-clickbait       0.78      0.69      0.73       510\n",
      "   clickbait       0.45      0.57      0.50       228\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       738\n",
      "   macro avg       0.62      0.63      0.62       738\n",
      "weighted avg       0.68      0.65      0.66       738\n",
      "\n",
      "AUC on binary labels: 0.6311661506707946\n",
      "AUC on probabilities: 0.666047471620227\n",
      "Confusion matrix:\n",
      "[[353 157]\n",
      " [ 98 130]]\n",
      "\n",
      "\n",
      "Test performance: XGDBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "no-clickbait       0.83      0.67      0.74       530\n",
      "   clickbait       0.44      0.65      0.53       208\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       738\n",
      "   macro avg       0.64      0.66      0.64       738\n",
      "weighted avg       0.72      0.67      0.68       738\n",
      "\n",
      "AUC on binary labels: 0.6637155297532655\n",
      "AUC on probabilities: 0.7220564223512336\n",
      "Confusion matrix:\n",
      "[[357 173]\n",
      " [ 72 136]]\n",
      "\n",
      "\n",
      "Test performance: GaussianNaiveBays\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "no-clickbait       0.73      0.81      0.77       484\n",
      "   clickbait       0.54      0.44      0.48       254\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       738\n",
      "   macro avg       0.64      0.62      0.63       738\n",
      "weighted avg       0.67      0.68      0.67       738\n",
      "\n",
      "AUC on binary labels: 0.6213964989913452\n",
      "AUC on probabilities: 0.6580659855534587\n",
      "Confusion matrix:\n",
      "[[390  94]\n",
      " [143 111]]\n",
      "\n",
      "\n",
      "Test performance: AdaBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "no-clickbait       0.78      0.66      0.72       505\n",
      "   clickbait       0.45      0.60      0.51       233\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       738\n",
      "   macro avg       0.62      0.63      0.62       738\n",
      "weighted avg       0.68      0.64      0.65       738\n",
      "\n",
      "AUC on binary labels: 0.6311222538562868\n",
      "AUC on probabilities: 0.6830663323843114\n",
      "Confusion matrix:\n",
      "[[334 171]\n",
      " [ 93 140]]\n",
      "\n",
      "\n",
      "-- Finished test reports --\n"
     ]
    }
   ],
   "source": [
    "classifiers.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODOS\n",
    "- **Scaling:** test performance if the features were scaled, this also requires optimizing again I think\n",
    "- **Feature reduction:** only use the top k features based on the mutial_information criterion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ir]",
   "language": "python",
   "name": "conda-env-ir-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
