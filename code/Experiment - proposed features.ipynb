{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replicating paper results\n",
    "This notebook will be used for replicating the results that are achieved in the paper. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "\n",
    "data_path = '../features/final_feat'\n",
    "feature_path = 'features.pkl'\n",
    "label_path = 'labels.npy'\n",
    "\n",
    "features = pd.read_pickle(path.join(data_path, feature_path))\n",
    "labels = np.load(path.join(data_path, label_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute class priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "n_nonclickbait = counts[0]\n",
    "n_clickbait = counts[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "Below is a list of the features that are going to be used.\n",
    "\n",
    "**Note**:\n",
    "The features are a subset of all the features that are being used in the original.\n",
    "We expect that scores will be slightly lower as we have less information about the post and the article. Still, the overal trend is expected to be the same because their results also so that the differences between using all features and 20 features is only a marginal improvement. \n",
    "\n",
    "Expected results training set\n",
    "\n",
    "| Measure   | Interval      |\n",
    "|-----------|---------------|\n",
    "| AUC       | 0.583 - 0.715 |\n",
    "| Accuracy  | 0.636 - 0.732 |\n",
    "| Precision | 0.743 - 0.75  |\n",
    "| Recall    | 0.721 - 0.92  |\n",
    "\n",
    "\n",
    "Expected results validation set  \n",
    "\n",
    "| Measure   | Interval      |\n",
    "|-----------|---------------|\n",
    "| AUC       | 0.653 - 0.8   |\n",
    "| Accuracy  | 0.725 - 0.812 |\n",
    "| Precision | 0.814 - 0.824 |\n",
    "| Recall    | 0.811 - 0.966 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numChars_post_title\n",
      "numChars_article_title\n",
      "numChars_post_image\n",
      "numChars_article_kw\n",
      "numChars_article_desc\n",
      "numChars_article_par\n",
      "numQuestionMarks_post_title\n",
      "numQuestionMarks_article_title\n",
      "numQuestionMarks_post_image\n",
      "numQuestionMarks_article_keywords\n",
      "numQuestionMarks_article_desc\n",
      "numQuestionMarks_article_par\n",
      "ratioChars_post_title_article_title\n",
      "ratioChars_post_title_post_image\n",
      "ratioChars_post_title_article_kw\n",
      "ratioChars_post_title_article_desc\n",
      "ratioChars_post_title_article_par\n",
      "ratioChars_article_title_post_image\n",
      "ratioChars_article_title_article_kw\n",
      "ratioChars_article_title_article_desc\n",
      "ratioChars_article_title_article_par\n",
      "ratioChars_post_image_article_kw\n",
      "ratioChars_post_image_article_desc\n",
      "ratioChars_post_image_article_par\n",
      "ratioChars_article_kw_article_desc\n",
      "ratioChars_article_kw_article_par\n",
      "ratioChars_article_desc_article_par\n",
      "diffChars_post_title_article_title\n",
      "diffChars_post_title_post_image\n",
      "diffChars_post_title_article_kw\n",
      "diffChars_post_title_article_desc\n",
      "diffChars_post_title_article_par\n",
      "diffChars_article_title_post_image\n",
      "diffChars_article_title_article_kw\n",
      "diffChars_article_title_article_desc\n",
      "diffChars_article_title_article_par\n",
      "diffChars_post_image_article_kw\n",
      "diffChars_post_image_article_desc\n",
      "diffChars_post_image_article_par\n",
      "diffChars_article_kw_article_desc\n",
      "diffChars_article_kw_article_par\n",
      "diffChars_article_desc_article_par\n",
      "isRetweet\n",
      "numWords_post_title\n",
      "numWords_article_title\n",
      "numWords_post_image\n",
      "numWordsUppercase_post_title\n",
      "numWordsUppercase_article_title\n",
      "numWordsUppercase_post_image\n",
      "numWordsTitlecase_post_title\n",
      "numWordsTitlecase_article_title\n",
      "numWordsTitlecase_post_image\n",
      "numFormalWords_post_title\n",
      "numFormalWords_article_title\n",
      "numFormalWords_post_image\n",
      "numStopWords_post_title\n",
      "numStopWords_article_title\n",
      "numStopWords_post_image\n",
      "ratioWords_post_title_article_title\n",
      "ratioWords_post_title_post_image\n",
      "ratioWords_article_title_post_image\n",
      "ratioWordsUppercase_post_title_article_title\n",
      "ratioWordsUppercase_post_title_post_image\n",
      "ratioWordsUppercase_article_title_post_image\n",
      "ratioWordsTitlecase_post_title_article_title\n",
      "ratioWordsTitlecase_post_title_post_image\n",
      "ratioWordsTitlecase_article_title_post_image\n",
      "ratioFormalWords_post_title_article_title\n",
      "ratioFormalWords_post_title_post_image\n",
      "ratioFormalWords_article_title_post_image\n",
      "ratioStopWords_post_title_article_title\n",
      "ratioStopWords_post_title_post_image\n",
      "ratioStopWords_article_title_post_image\n",
      "diffWords_post_title_article_title\n",
      "diffWords_post_title_post_image\n",
      "diffWords_article_title_post_image\n",
      "diffWordsUppercase_post_title_article_title\n",
      "diffWordsUppercase_post_title_post_image\n",
      "diffWordsUppercase_article_title_post_image\n",
      "diffWordsTitlecase_post_title_article_title\n",
      "diffWordsTitlecase_post_title_post_image\n",
      "diffWordsTitlecase_article_title_post_image\n",
      "diffFormalWords_post_title_article_title\n",
      "diffFormalWords_post_title_post_image\n",
      "diffFormalWords_article_title_post_image\n",
      "diffStopWords_post_title_article_title\n",
      "diffStopWords_post_title_post_image\n",
      "diffStopWords_article_title_post_image\n",
      "numTags{'NNP'}_post_title\n",
      "numTags{'NNP'}_article_title\n",
      "ratioTags_{'NNP'}_post_title_article_title\n",
      "diffTags_{'NNP'}_post_title_article_title\n",
      "numTags{'DT'}_post_title\n",
      "numTags{'DT'}_article_title\n",
      "ratioTags_{'DT'}_post_title_article_title\n",
      "diffTags_{'DT'}_post_title_article_title\n",
      "numTags{'PRP'}_post_title\n",
      "numTags{'PRP'}_article_title\n",
      "ratioTags_{'PRP'}_post_title_article_title\n",
      "diffTags_{'PRP'}_post_title_article_title\n",
      "sentiment_post_title\n",
      "sentiment_article_title\n",
      "diffSentiment_post_title_article_title\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(x) for x in features.columns] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization by grid search\n",
    "\n",
    "The authors did not explain what parameters their optimal classifier used. They also did not explain how these classifier where optimized.\n",
    "\n",
    "Therefore, we made the decision to apply a grid search to find suitable parameters (such as #estimators etc.). The grids are given below.\n",
    "\n",
    "The following settings are used during this grid search: \n",
    "- **10-fold cross validation with shuffeled data.** This will remove bias from our estimation as the data is shuffeld and the cross validation is a different one then used during testing. \n",
    "- **F1-metric as performance measure.** The classes of clickbait vs no-clickbait are unbalanced, making measure as accuracy useless (70% accuracy could mean that we only assign to one class!). As we want the performance for both classes to be equally good, the F1 score is used which is the harmonic mean of precision and recall. \n",
    "\n",
    "## GRIDS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_grid = {\n",
    "    'criterion': ['entropy'],\n",
    "    'n_estimators': [10,25,50,100],\n",
    "    'max_depth': [1,3,5,None],\n",
    "    'max_features': [5,10,15, None],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "adaboost_grid = {\n",
    "    'n_estimators': [10,25,50,100],\n",
    "    'learning_rate': [0.1,0.2,0.3],\n",
    "    'base_estimator__max_depth': [1,3,5,None],\n",
    "    'base_estimator__criterion': ['entropy'],\n",
    "    'base_estimator__class_weight': ['balanced'],\n",
    "    \n",
    "}\n",
    "\n",
    "xgb_grid = {\n",
    "    'objective': ['binary:logistic'],\n",
    "    'learning_rate': [0.1,0.2,0.3],\n",
    "    'n_estimators': [10,25,50,100],\n",
    "    'max_depth': [1,3,5,7,9],\n",
    "    'scale_pos_weight': [n_nonclickbait / n_clickbait] \n",
    "}\n",
    "\n",
    "# This classifier does not really have parameters to tweak\n",
    "# Use default values to not break the pipeline\n",
    "naivebayes_grid = {\n",
    "    'priors': [None], # priors are computed by the algorithm\n",
    "    'var_smoothing': [1e-9]\n",
    "}\n",
    "\n",
    "svc_grid = {\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "classifiers_options = [\n",
    "    {\n",
    "        'name': 'RandomForest',\n",
    "        'clf': RandomForestClassifier(),\n",
    "#         'grid': randomforest_grid,\n",
    "        'optimized_param': {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 5, 'max_features': 15, 'n_estimators': 50}\n",
    "    },\n",
    "    {\n",
    "        'name': 'XGDBoost',\n",
    "        'clf': XGBClassifier(),\n",
    "#         'grid': xgb_grid,\n",
    "        'optimized_param': {'learning_rate': 0.2, 'max_depth': 1, 'n_estimators': 100, 'objective': 'binary:logistic', 'scale_pos_weight': 2.227034120734908}\n",
    "    },\n",
    "    {\n",
    "        'name': 'GaussianNaiveBays',\n",
    "        'clf': GaussianNB(),\n",
    "        'optimized_param': {} ## Can not be optimized\n",
    "\n",
    "    },\n",
    "    {\n",
    "        'name': 'AdaBoost',\n",
    "        'clf': AdaBoostClassifier(DecisionTreeClassifier()),\n",
    "#         'grid': adaboost_grid\n",
    "        'optimized_param': {'base_estimator__class_weight': 'balanced', 'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': 1, 'learning_rate': 0.3, 'n_estimators': 100}\n",
    "    },\n",
    "    # Takes to long to optimize so we just assume that the linear kernel is good enough\n",
    "#     {\n",
    "#         'name': 'SVM',\n",
    "#         'clf': SVC(probability=True),\n",
    "# # #         'grid': svc_grid,\n",
    "#         'optimized_param': {'kernel': 'linear'}\n",
    "#     }\n",
    "]\n",
    "\n",
    "import classification\n",
    "classifiers = classification.Classifiers(features,labels, classifiers_options)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform the grid search - optimize on F1\n",
    "\n",
    "This may take a while.  \n",
    "Output = optimized settings per classifier, which can be used in the model with the `optimized_param` key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Start optimizing by grid search --\n",
      "Optimizing: RandomForest\n",
      "Optimal settings RandomForest:\n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 5, 'max_features': 15, 'n_estimators': 50}\n",
      "Optimizing: XGDBoost\n",
      "Optimal settings XGDBoost:\n",
      "{'learning_rate': 0.2, 'max_depth': 1, 'n_estimators': 100, 'objective': 'binary:logistic', 'scale_pos_weight': 2.227034120734908}\n",
      "Optimizing: AdaBoost\n",
      "Optimal settings AdaBoost:\n",
      "{'base_estimator__class_weight': 'balanced', 'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': 1, 'learning_rate': 0.3, 'n_estimators': 100}\n",
      "-- Finished optimizing -- \n"
     ]
    }
   ],
   "source": [
    "classifiers.optimize(metric='f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance - optimized on F1\n",
    "\n",
    "The authors test their classifiers by doing a 10-fold internal (?) cross validation. To have a fair comparison, we will use the same strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Cross validation with 10-folds --\n",
      "Cross validation performance RandomForest:\n",
      "TRAIN\n",
      "train_accuracy     0.790792\n",
      "train_precision    0.651681\n",
      "train_f1           0.674160\n",
      "train_roc_auc      0.850985\n",
      "train_recall       0.698416\n",
      "\n",
      "TEST\n",
      "test_accuracy     0.725504\n",
      "test_precision    0.551277\n",
      "test_f1           0.569722\n",
      "test_roc_auc      0.744672\n",
      "test_recall       0.594166\n",
      "\n",
      "\n",
      "Cross validation performance XGDBoost:\n",
      "TRAIN\n",
      "train_accuracy     0.747594\n",
      "train_precision    0.574388\n",
      "train_f1           0.637206\n",
      "train_roc_auc      0.809124\n",
      "train_recall       0.715509\n",
      "\n",
      "TEST\n",
      "test_accuracy     0.715718\n",
      "test_precision    0.533675\n",
      "test_f1           0.585330\n",
      "test_roc_auc      0.760781\n",
      "test_recall       0.653341\n",
      "\n",
      "\n",
      "Cross validation performance GaussianNaiveBays:\n",
      "TRAIN\n",
      "train_accuracy     0.436219\n",
      "train_precision    0.341750\n",
      "train_f1           0.492686\n",
      "train_roc_auc      0.706546\n",
      "train_recall       0.883042\n",
      "\n",
      "TEST\n",
      "test_accuracy     0.433956\n",
      "test_precision    0.340102\n",
      "test_f1           0.487934\n",
      "test_roc_auc      0.686705\n",
      "test_recall       0.872580\n",
      "\n",
      "\n",
      "Cross validation performance AdaBoost:\n",
      "TRAIN\n",
      "train_accuracy     0.756947\n",
      "train_precision    0.586012\n",
      "train_f1           0.652044\n",
      "train_roc_auc      0.830875\n",
      "train_recall       0.734946\n",
      "\n",
      "TEST\n",
      "test_accuracy     0.700697\n",
      "test_precision    0.513612\n",
      "test_f1           0.571446\n",
      "test_roc_auc      0.740207\n",
      "test_recall       0.649777\n",
      "\n",
      "\n",
      "-- Finished cross validation --\n"
     ]
    }
   ],
   "source": [
    "classifiers.cross_val()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results show that some classifiers have a extremely low recall. We dont have access to the actual predictions that were made, so to analyse the results we do another test on a random subset. This gives us access to the confusion matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Performance on split: 70% train - 30% split --\n",
      "Test performance: RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "no-clickbait       0.81      0.78      0.80       521\n",
      "   clickbait       0.52      0.57      0.54       217\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       738\n",
      "   macro avg       0.67      0.67      0.67       738\n",
      "weighted avg       0.73      0.72      0.72       738\n",
      "\n",
      "AUC on binary labels: 0.6740051478457769\n",
      "AUC on probabilities: 0.7432312904110315\n",
      "Confusion matrix:\n",
      "[[407 114]\n",
      " [ 94 123]]\n",
      "\n",
      "\n",
      "Test performance: XGDBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "no-clickbait       0.79      0.74      0.76       500\n",
      "   clickbait       0.52      0.58      0.55       238\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       738\n",
      "   macro avg       0.65      0.66      0.66       738\n",
      "weighted avg       0.70      0.69      0.69       738\n",
      "\n",
      "AUC on binary labels: 0.6609159663865547\n",
      "AUC on probabilities: 0.7283109243697479\n",
      "Confusion matrix:\n",
      "[[371 129]\n",
      " [100 138]]\n",
      "\n",
      "\n",
      "Test performance: GaussianNaiveBays\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "no-clickbait       0.78      0.27      0.40       503\n",
      "   clickbait       0.35      0.84      0.49       235\n",
      "\n",
      "   micro avg       0.45      0.45      0.45       738\n",
      "   macro avg       0.57      0.56      0.45       738\n",
      "weighted avg       0.65      0.45      0.43       738\n",
      "\n",
      "AUC on binary labels: 0.5554714267585974\n",
      "AUC on probabilities: 0.6718793621251217\n",
      "Confusion matrix:\n",
      "[[135 368]\n",
      " [ 37 198]]\n",
      "\n",
      "\n",
      "Test performance: AdaBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "no-clickbait       0.82      0.75      0.78       510\n",
      "   clickbait       0.53      0.64      0.58       228\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       738\n",
      "   macro avg       0.68      0.69      0.68       738\n",
      "weighted avg       0.73      0.71      0.72       738\n",
      "\n",
      "AUC on binary labels: 0.6949174406604748\n",
      "AUC on probabilities: 0.7331570347437221\n",
      "Confusion matrix:\n",
      "[[380 130]\n",
      " [ 81 147]]\n",
      "\n",
      "\n",
      "-- Finished test reports --\n"
     ]
    }
   ],
   "source": [
    "classifiers.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ir]",
   "language": "python",
   "name": "conda-env-ir-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
